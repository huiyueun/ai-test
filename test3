data_generator.py

import json
import random
import zipfile
from pathlib import Path
import copy
import openai
import time
import os

import llm_utils

# Sample data pools for English and Korean UI elements
hero_titles = ["Stranger Things", "Breaking Bad", "The Crown", "Top Gun: Maverick", "Live News Stream"]
hero_titles_ko = ["더 글로리", "오징어 게임", "기생충", "이상한 변호사 우영우", "라이브 뉴스 스트림"]

buttons = [["Play", "More Info"], ["Watch", "Details"], ["Install"], ["Preview", "Add to List"]]

tabs_pool = [
    ["Live", "Apps", "For You"],
    ["Home", "TV Shows", "Movies", "My List"],
    ["All", "Gaming", "Music", "News"],
    ["Top", "New", "Games", "Education"],
    ["home_i_icon_mode_search.png", "lifestyle_home_i_mode_art.svg", "home_i_icon_mode_lifeplus_normal.png", "home_i_icon_mode_game_selected.png", "home_i_icon_system_settings.svg"]
]
tabs_pool_ko = [
    ["라이브", "앱", "취향저격"],
    ["홈", "TV 프로그램", "영화", "내 목록"],
    ["전체", "게임", "음악", "뉴스"]
]

sections_pool = ["Continue Watching", "Recommended", "Trending Now", "Popular Apps", "Top Games"]
sections_pool_ko = ["이어보기", "추천 콘텐츠", "인기 콘텐츠", "내가 찜한 콘텐츠", "요즘 뜨는 앱"]

toolbar_sets = [
    ["home", "photos", "settings"],
    ["search", "home", "genres", "settings"],
    ["home", "shorts", "subscriptions", "library"],
    ["search", "categories", "my apps"]
]
toolbar_sets_ko = [["홈", "사진", "설정"], ["검색", "홈", "카테고리", "설정"]]

apps_list = ["Netflix", "YouTube", "Disney+", "Spotify", "Hulu", "Zoom", "Twitch", "Prime Video"]
apps_list_ko = ["넷플릭스", "유튜브", "디즈니+", "멜론", "웨이브", "쿠팡플레이", "TVING | 티빙", "왓챠"]

regions = ["top", "mid", "btm"]

def generate_screen_json(use_korean: bool):
    use_toolbar = random.random() < 0.8
    use_hero = random.random() < 0.9
    use_apps = random.random() < 0.3
    use_grid = random.random() < 0.1

    if use_korean:
        lang = "ko"
        hero_pool = hero_titles_ko
        tabs_pool_local = tabs_pool_ko
        section_pool_local = sections_pool_ko
        toolbar_pool = toolbar_sets_ko
        app_pool = apps_list_ko
    else:
        lang = "en"
        hero_pool = hero_titles
        tabs_pool_local = tabs_pool
        section_pool_local = sections_pool
        toolbar_pool = toolbar_sets
        app_pool = apps_list

    screen_type = random.choice(["home", "detail", "store", "video", "gaming", "grid"])
    #layout = {"res": "1920x1080", "lang": lang, "screen_type": screen_type}
    #layout = {"screen_type": screen_type}
    layout = {}

    if use_toolbar:
        use_left = use_grid = random.random() < 0.7
        if use_left:
            layout["tb:left"] = random.choice(toolbar_pool)
        else:
            layout["tb:right"] = random.choice(toolbar_pool)

    if use_hero and screen_type in ["home", "store", "video", "gaming"]:
        hero = random.choice(hero_pool)
        btns = random.choice(buttons)
        layout["hero:top"] = f"{hero} | btn: {', '.join(btns)}"

    if screen_type in ["home", "store", "video", "gaming"]:
        tabs = random.choice(tabs_pool_local)
        tabs = copy.copy(tabs)
        layout[f"tabs:{random.choice(regions)}"] = tabs

    if use_grid and screen_type in ["store", "grid"]:
        layout["grid:main*"] = {
            "title": "Top Picks" if lang == "en" else "추천 앱",
            "items": random.sample(app_pool, 6)
        }

    for _ in range(random.randint(1, 3)):
        list_key = f"list:{random.choice(regions)}"
        layout[list_key] = []
        for _ in range(random.randint(1, 3)):
            use_title = random.random() < 0.4
            title = random.choice(section_pool_local)
            items = random.sample(hero_pool + hero_titles + app_pool, random.randint(1, 5))
            if use_title:
                layout[list_key].append(f"[{title}]: {', '.join(items)}")
            else:
                layout[list_key].append(f"{', '.join(items)}")

    if use_apps:
        apps_key = f"apps:{random.choice(regions)}"
        items = random.sample(app_pool, random.randint(1, 5))
        layout[apps_key] = f"{', '.join(items)}"

    return layout

def extract_layouts_from_input_file(input_file_path):
    with open(input_file_path, "r") as file:
        return json.load(file)

def generate_screen_layout(layouts, index, use_korean):
    if index < len(layouts):
        return layouts[index]
    else:
        return generate_screen_json(use_korean)

shared_limiter = llm_utils.RateLimiter(max_calls=20, per_seconds=61)
def generate_dataset(n=20, output_file="synthetic_tv_data_kr.jsonl"):
    layouts = extract_layouts_from_input_file("sample_data/input.json")
    with open(output_file, "a") as f:
        for i in range(n):
            formatted = json.dumps(
                (layouts, i, True), ensure_ascii=False, indent=2)
            print(formatted)
            summary = llm_utils.llm_request_with_rate_limit(
                llm_utils.generate_summary_llm,
                formatted,
                True,
                rate_limiter=shared_limiter)
            
            print(f"\n summary {i+1} / {n} : \n{summary}\n")
            record = {
                "input": formatted,
                "output": summary
            }
            f.write(json.dumps(record, ensure_ascii=False) + "\n")

if __name__ == "__main__":
    generate_dataset(n=500)



llm_utils.py
import time
import os
import openai
import json
from typing import Callable, Any
import re

class RateLimiter:
    def __init__(self, max_calls: int, per_seconds: int):
        self.max_calls = max_calls
        self.per_seconds = per_seconds
        self.window_start = time.time()
        self.calls_in_window = 0

    def wait_if_needed(self):
        now = time.time()
        elapsed = now - self.window_start

        if self.calls_in_window >= self.max_calls:
            if elapsed < self.per_seconds:
                wait_time = self.per_seconds - elapsed
                print(f"Rate limit reached. Waiting {wait_time:.1f} seconds...")
                time.sleep(wait_time)
            self.window_start = time.time()
            self.calls_in_window = 0
        
        self.calls_in_window += 1

# Set your API key
API_KEY = os.getenv('SHUTTLE_API_KEY')
MODEL = "gauss2.2-37b"
client = openai.OpenAI(
     base_url="https://inference-webtrial-api.shuttle.sr-cloud.com/gauss2-2-37b-instruct/v1/",
     api_key="dummyvalue",
     default_headers={
         "Authorization": f"Basic {API_KEY}",
         "Content-Type": "application/json",
     },
)

def request_llm(prompt: str):
    messages = [
        {"role": "user", "content": prompt},
    ]

    print(prompt)

    assistant_response_content = ""
    with client.chat.completions.create(
        model=f"{MODEL}",
        messages=messages,
        stream=True
    ) as stream:
        for chunk in stream:
            if chunk.choices[0].delta and chunk.choices[0].delta.content:
                # Accumulate the content only if it's not None
                assistant_response_content += chunk.choices[0].delta.content
                # yield f"data: {chunk.choices[0].delta.content}\n\n"
            if chunk.choices[0].finish_reason == "stop":
                break  # Stop if the finish reason is 'stop'
 
    print(assistant_response_content)
    return assistant_response_content

def clean_output(output: str) -> str:
    return re.sub(r"^\s*[\-\•]?\s*(\d+[\.\)])?\s*", "", output)

def clean_batch_output_lines(output: str) -> list[str]:
    lines = output.strip().split('\n')
    cleaned = []

    for line in lines:
        cleaned_line = clean_output(line)
        if cleaned_line:
            cleaned.append(cleaned_line.strip())

    return cleaned

def translate_to_korean_batch(phrases: list[str]):
    prompt = (
        "Translate each of the following UI screen descripton into Korean. "
        "Each translation should be a short phrase, not a full sentence. "
        "For example, instead of '프로필 설정 페이지가 표시됩니다.', return '프로필 설정 페이지'.\n"
        "If the English phrase contains the name of an app or subject (e.g., 'music app'), place it before the main label using '의'. "
        "like '음악 앱의 홈 화면'. Do not use parentheses to indicate the subject.\n"
        "Output the transalations as a plain list, one per line, without any numbering, bullet points, or extra characters.\n\n"
        "Enaglish phrases:\n"
    )
    for phrase in phrases:
        prompt += f" - {phrase}\n"
    prompt += "\nKorean translations:"

    response = request_llm(prompt)
    # Split the response by newlines to get individual translations
    return clean_batch_output_lines(response)

def generate_summary_llm(screen: str, is_korean: bool):
    prompt = (
        "You are given a list of screens with their UI structure. Your task is to generate one full summary per screen.\n"
        f"Each summary should:\n"
        " - Be on its own line (no merging)\n"
        " - Be standalone (not referencing other summaries)\n"
        f" - Be natural and clear in {'polite Korean (존댓말)' if is_korean else 'English'}\n"
        " - Not include screen numbers, labels, or bullet points\n"
        " - Use a concise, friendly tone.\n"
        "Follow these guidelines for generating each summary\n"
        "** Visual Order **\n"
        " * Follow the visual structure from top to bottom, left to right.\n"
        " * If multiple items are in the same region (e.g., mid), assume tabs are above other items.\n"
        "** Handling Lists **\n"
        " * If a list contains many items, mention only a few and use expressions like 'such as A, B, etc.'\n"
        "** Handling non-human-readable items **\n"
        " * If the name contains meaningful words (e.g., home_icon_search_selected.png), interpret them naturally, such as 'a selected search icon'\n"
        " * If the name is unclear or generic (e.g., 123.png), you can either describe it vaguely as 'an image' or 'a picture' or simply *ignore it* in the summary\n"
        "** Keyword Interpretation **\n"
        " * tb:left: left toolbar\n"
        " * tb:right: right toolbar\n"
        " * apps:mid: app icons in the middle area\n"
        " * btn: button\n"
        "** Miscellaneous **\n"
        " * If the screen contains a message or sentence shown to user (like banner or tagline), "
        "do not paraphrase or interpret it. Instead, state that the message is shown on screen. Use **translated and shortened version** when refering to it.\n"
        " * When referring to UI labels, do not quote them or include raw tags like 'btn:' or 'txt:'\n"
        " * If a keyword or file name is too ambiguous or noisy, it's okay to *skip it* in the summary.\n\n"
    )

    input = f"Screen structures: \n{screen}\n"

    prompt += input

    response = request_llm(prompt)
    return clean_output(response)

# Generate batch summary using LLM
def generate_summary_llm_batch(formatted_inputs: list[str], short_summaries: list[str], is_korean: bool):
    prompt = (
        "You are given a list of screens with their UI structure and short summaries. Your task is to generate one full summary per screen.\n"
        "Use the short summary as a guide, but do not copy or repeat it. Expand on it using screen structure.\n"
        f"Each summary should:\n"
        " - Be on its own line (no merging)\n"
        " - Be standalone (not referencing other summaries)\n"
        f" - Be natural and clear in {'polite Korean (존댓말)' if is_korean else 'English'}\n"
        " - Not include screen numbers, labels, or bullet points\n"
        " - Use a concise, friendly tone.\n"
        "Follow these guidelines for generating each summary\n"
        "** Visual Order **\n"
        " * Follow the visual structure from top to bottom, left to right.\n"
        " * If multiple items are in the same region (e.g., mid), assume tabs are above other items.\n"
        "** Handling Lists **\n"
        " * If a list contains many items, mention only a few and use expressions like 'such as A, B, etc.'\n"
        "** Handling non-human-readable items **\n"
        " * If the name contains meaningful words (e.g., home_icon_search_selected.png), interpret them naturally, such as 'a selected search icon'\n"
        " * If the name is unclear or generic (e.g., 123.png), you can either describe it vaguely as 'an image' or 'a picture' or simply *ignore it* in the summary\n"
        "** Keyword Interpretation **\n"
        " * tb:left: left toolbar\n"
        " * tb:right: right toolbar\n"
        " * apps:mid: app icons in the middle area\n"
        " * btn: button\n"
        "** Miscellaneous **\n"
        " * If the screen contains a message or sentence shown to user (like banner or tagline), "
        "do not paraphrase or interpret it. Instead, state that the message is shown on screen. Use **translated and shortened version** when refering to it.\n"
        " * When referring to UI labels, do not quote them or include raw tags like 'btn:' or 'txt:'\n"
        " * If a keyword or file name is too ambiguous or noisy, it's okay to *skip it* in the summary.\n\n"
    )

    batch_input = ""
    for i, (screen, summary) in enumerate(zip(formatted_inputs, short_summaries)):
        batch_input += f"### Screen {i + 1}\n"
        batch_input += f"Screen structures: \n{screen}\n"
        batch_input += f"Short summary: {summary}\n\n"

    prompt += batch_input

    response = request_llm(prompt)
    return clean_batch_output_lines(response)

   
    # prompt += "\nLayout:"
    # prompt += json.dumps(layout_json, ensure_ascii=False)
    # prompt += "\nShort Description:" + short_summary
    # prompt += "\nSummary:"

    # return request_llm(prompt)


def llm_request_with_rate_limit(
    func: Callable,
    *args: Any,
    rate_limiter: RateLimiter,
):
    result = None
    rate_limiter.wait_if_needed()

    try:
        result = func(*args)
    except Exception as e:
        print(f"Error processing item: {e}")

    return result

for idx, screen in enumerate(screens):
    if "qwen" in save_dir_merged.lower():
        prompt = f"<|im_start|>user\nGenerate a summary for the following screen in Korean:\n{screen}\n<|im_end|>\n<|im_start|>assistant"
    else:
        prompt = f"<bos><start_of_turn>user\nGenerate a summary for the following screen in Korean:\n{screen}\n<end_of_turn>\n<start_of_turn>model"

    command = [
        LLAMA_CLI_BIN,
        "-m", GGUF_MODEL_PATH,
        "-p", prompt,
        "--n-predict", str(MAX_TOKENS),
        "--temp", "1.0",
        "--top-p", "0.95",
        "--top-k", "64"
    ]

    print(f"\n=== [Screen {idx+1}] Running command ===")
    print(" ".join(command))

    try:
        process = subprocess.Popen(
            command,
            stdout=subprocess.PIPE,
            stderr=subprocess.STDOUT,
            text=True
        )

        output, _ = process.communicate(timeout=90)
        print(f"[Screen {idx+1} Output]\n{output}")

    except subprocess.TimeoutExpired:
        process.kill()
        print(f"[Screen {idx+1}] Timeout occurred.")

    except Exception as e:
        print(f"[Screen {idx+1}] Error: {e}")

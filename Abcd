import gradio as gr
from llama_cpp import Llama
import os
import sys

# --- 설정값 불러오기 ---
sys.path.append(os.path.dirname(os.path.dirname(__file__)))
from config import save_dir_merged

GGUF_MODEL_PATH = os.path.join(save_dir_merged, "model.gguf")
MAX_TOKENS = 256

# --- 모델 로드 ---
print("🔄 모델 로딩 중...")
llm = Llama(
    model_path=GGUF_MODEL_PATH,
    n_ctx=2048,
    n_threads=8,         # CPU 스레드 수
    n_batch=256,
    n_gpu_layers=20      # GPU 사용시 적절히 조정 (없으면 0)
)
print("✅ 모델 로딩 완료")

# --- 요약 생성 함수 ---
def generate_summary(screen_json: str) -> str:
    if not screen_json.strip():
        return "❗ JSON 입력이 비어있습니다."

    if "qwen" in save_dir_merged:
        prompt = f"<|im_start|>user\n다음 화면을 한국어로 요약해줘:\n{screen_json}\n<|im_end|>\n<|im_start|>assistant"
    else:
        prompt = f"<bos><start_of_turn>user\n다음 화면을 한국어로 요약해줘:\n{screen_json}\n<end_of_turn>\n<start_of_turn>model"

    response = llm(
        prompt,
        max_tokens=MAX_TOKENS,
        temperature=1.0,
        top_p=0.95,
        top_k=64,
        stop=["<|im_end|>", "<end_of_turn>"]
    )
    return response["choices"][0]["text"].strip()

# --- Gradio UI ---
with gr.Blocks() as demo:
    gr.Markdown("# 🧠 LLaMA GGUF 요약기")
    gr.Markdown("입력된 UI 화면 구조(JSON)를 한국어로 요약합니다.")

    with gr.Row():
        input_json = gr.Textbox(label="📥 화면 JSON 입력", lines=20, placeholder="여기에 JSON을 붙여넣으세요")
        output_text = gr.Textbox(label="📤 요약 결과", lines=20)

    run_button = gr.Button("📝 요약 실행")
    run_button.click(fn=generate_summary, inputs=input_json, outputs=output_text)

# 실행
if __name__ == "__main__":
    demo.launch()

from unsloth import FastModel
import torch

# âœ… Unsloth ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°
model, tokenizer = FastModel.from_pretrained(
    model_name = "unsloth/Meta-Llama-3-8B-Instruct-bnb-4bit",
    max_seq_length = 2048,
    load_in_4bit = True,
)

# âœ… í•œê¸€ ì§ˆë¬¸ ì…ë ¥
prompt = "í•œêµ­ì˜ ìˆ˜ë„ëŠ” ì–´ë””ì¸ê°€ìš”?"
inputs = tokenizer(prompt, return_tensors="pt").to(model.device)

# âœ… ëª¨ë¸ ì¶”ë¡ 
with torch.no_grad():
    outputs = model.generate(**inputs, max_new_tokens=50)

# âœ… ê²°ê³¼ ì¶œë ¥
print("ğŸ¦¥ ëª¨ë¸ ì‘ë‹µ:")
print(tokenizer.decode(outputs[0], skip_special_tokens=True))
